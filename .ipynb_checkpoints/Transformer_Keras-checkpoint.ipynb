{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from h5py import File\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.initializers import *\n",
    "from keras.activations import *\n",
    "import tensorflow as tf\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "\n",
    "# Data Parameters\n",
    "data_file = 'data/en2de.h5'\n",
    "valid_data_file = 'data/en2de.valid.h5'\n",
    "dict_file = 'data/en2de_word.txt'\n",
    "\n",
    "# Transformer Parameters\n",
    "d_model = 512 # Embedding Demension\n",
    "d_ff = 2048 # Feed-Forward Network's Hidden Size\n",
    "d_k = d_v = 64 # = d_model / head\n",
    "N = 6 # Num of Encoder / Decoder Layer's Stack\n",
    "head = 8 # Num of Multi-Head Attention's Head\n",
    "len_limit = 999\n",
    "\n",
    "dropout = 0.1 # Dropout\n",
    "warmup_steps = 4000 # Using When Evaluate Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use En2De Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenList:\n",
    "    def __init__(self, token_list):\n",
    "        self.id2t = ['<PAD>', '<UNK>', '<S>', '</S>'] + token_list\n",
    "        self.t2id = {v: k for k, v in enumerate(self.id2t)}\n",
    "\n",
    "    def id(self, x):    \n",
    "        return self.t2id.get(x, 1)\n",
    "\n",
    "    def token(self, x):    \n",
    "        return self.id2t[x]\n",
    "\n",
    "    def num(self):        \n",
    "        return len(self.id2t)\n",
    "\n",
    "    def start_id(self):  \n",
    "        return 2\n",
    "\n",
    "    def end_id(self):    \n",
    "        return 3\n",
    "    \n",
    "\n",
    "def make_dict(dict_file):\n",
    "    with open(dict_file, encoding=\"utf-8\") as f:\n",
    "        _list = list(ll for ll in f.read().split('\\n') if ll != \"\")\n",
    "    mid_pos = _list.index('<@@@>') # Seperate En & De\n",
    "    input_tokens = TokenList(_list[:mid_pos])\n",
    "    output_tokens = TokenList(_list[mid_pos + 1:])\n",
    "    return input_tokens, output_tokens\n",
    "\n",
    "\n",
    "def make_data(data_file):\n",
    "    with File(data_file) as df:\n",
    "        X, Y = df['X'][:], df['Y'][:]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_tokens, output_tokens = make_dict(dict_file)\n",
    "    x_train, y_train = make_data(data_file)\n",
    "    x_valid, y_valid = make_data(valid_data_file)\n",
    "\n",
    "    input_vocab_size = input_tokens.num()\n",
    "    output_vocab_size = output_tokens.num()\n",
    "    \n",
    "    print('English DictNum:', input_tokens.num())\n",
    "    print('Deutsche DictNum:', output_tokens.num())\n",
    "    print('Train Shapes:',  x_train.shape, y_train.shape)\n",
    "    print('Valid Shapes:', x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(max_len):\n",
    "    PE = np.array([\n",
    "        [pos / np.power(10000, 2 * i / d_model) for i in range(d_model)]\n",
    "        if pos != 0 else np.zeros(d_model) for pos in range(max_len)\n",
    "    ]) # np.power(10000, 2 * (j // 2) / d_emb) ??? Why?\n",
    "    PE[1:, 0::2] = np.sin(PE[1:, 0::2]) # 2i\n",
    "    PE[1:, 1::2] = np.cos(PE[1:, 1::2]) # 2i + 1\n",
    "    \n",
    "    return PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self):\n",
    "        print(\"Multi-Head Attention Layer Generated\")\n",
    "        self.Q_linear_transform_layers = []\n",
    "        self.K_linear_transform_layers = []\n",
    "        self.V_linear_transform_layers = []\n",
    "        \n",
    "        for _ in range(head):\n",
    "            self.Q_linear_transform_layers.append(Dense(d_k, use_bias=False))\n",
    "            self.K_linear_transform_layers.append(Dense(d_k, use_bias=False))\n",
    "            self.V_linear_transform_layers.append(Dense(d_v, use_bias=False))\n",
    "        \n",
    "        self.normarlization_layer = LayerNormalization()\n",
    "        self.output_linear_transfrom_layer = Dense(d_model)\n",
    "        \n",
    "    def __call__(self, Q, K, V, mask=None):\n",
    "        attentions = []\n",
    "        outputs = [] # ?\n",
    "        \n",
    "        for i in range(head):\n",
    "            WQ = self.Q_linear_transform_layers[i](Q)\n",
    "            WK = self.K_linear_transform_layers[i](K)\n",
    "            WV = self.V_linear_transform_layers[i](V)\n",
    "            output, attention = self.scaled_dot_product_attention(WQ, WK, WV)\n",
    "            attentions.append(attention)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        attention_result = Concatenate()(attentions)\n",
    "        output_result = Concatenate()(outputs)\n",
    "        output = self.output_linear_transfrom_layer(output_result)\n",
    "        output += Q\n",
    "        \n",
    "        return self.normarlization_layer(output), attention\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        num = tf.matmul(Q, tf.transpose(K, perm=[0, 2, 1]))\n",
    "        denum = np.sqrt(d_model)\n",
    "        attention = tf.matmul(softmax(num / denum), V)\n",
    "        output = tf.matmul(attention, tf.transpose(V, perm=[0, 2, 1]))\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Position-wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForwardNetwork:\n",
    "    def __init__(self):\n",
    "        print(\"Position-Wise Feed Forward Network Generated\")\n",
    "        self.linear_transform_layer_1 = Dense(d_model)\n",
    "        self.relu_layer = Dense(d_model, activation='relu')\n",
    "        self.linear_transform_layer_2 = Dense(d_model)\n",
    "        self.normarlization_layer = LayerNormalization()\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        output = self.linear_transform_layer_1(x)\n",
    "        output = self.relu_layer(output)\n",
    "        output = self.linear_transform_layer_2(output)\n",
    "        output += x\n",
    "        \n",
    "        return self.normarlization_layer(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer:\n",
    "    def __init__(self):\n",
    "        print(\"Encoder Layer Generated\")\n",
    "        self.multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.position_wise_feed_forward_network = PositionWiseFeedForwardNetwork()\n",
    "        \n",
    "    def __call__(self, encoder_input, mask=None):\n",
    "        encoder_output, attention = self.multi_head_attention_layer(encoder_input, encoder_input, encoder_input, mask)\n",
    "        encoder_output = self.position_wise_feed_forward_network(encoder_output)\n",
    "        \n",
    "        return encoder_output, attention\n",
    "    \n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.input_embedding =  Embedding(input_vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(len_limit, d_model, trainable=False,\n",
    "                                              weights=[positional_encoding(len_limit)])\n",
    "        self.layers = [EncoderLayer() for _ in range(N)]\n",
    "        \n",
    "    def __call__(self, encoder_input):\n",
    "        encoder_output = self.input_embedding(encoder_input) + self.positional_embedding(tf.constant([i for i in range(input_vocab_size)]))\n",
    "        encoder_attentions = []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            encoder_output, encoder_attention = layer(encoder_output)\n",
    "            encoder_attentions.append(encoder_attention)\n",
    "            \n",
    "        return encoder_output, encoder_attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer:\n",
    "    def __init__(self):\n",
    "        print(\"Decoder Layer Generated\")\n",
    "        self.multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.masked_multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.position_wise_feed_forward_network = PositionWiseFeedForwardNetwork()\n",
    "        \n",
    "    def __call__(self, decoder_input, encoder_output, mask=None):\n",
    "        decoder_output, decoder_attention = self.masked_multi_head_attention_layer(decoder_input, decoder_input, decoder_input, mask)\n",
    "        decoder_output, decoder_encoder_attention = self.masked_multi_head_attention_layer(decoder_output, encoder_output, encoder_output, None)\n",
    "        decoder_output = self.position_wise_feed_forward_network(decoder_output)\n",
    "        \n",
    "        return decoder_output, decoder_attention, decoder_encoder_attention\n",
    "        \n",
    "class Decoder:\n",
    "    def __init__(self):\n",
    "        self.output_embedding =  Embedding(output_vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(len_limit, d_model, trainable=False,\n",
    "                                              weights=[positional_encoding(len_limit)])\n",
    "        self.layers = [DecoderLayer() for _ in range(N)]\n",
    "        \n",
    "    def __call__(self, decoder_input, encoder_input, encoder_output):\n",
    "        decoder_output = self.output_embedding(encoder_input) + self.positional_embedding(tf.constant([i for i in range(output_vocab_size)]))\n",
    "        attention_mask = self.get_attention_mask(decoder_input, encoder_input)\n",
    "        \n",
    "        decoder_attentions, decoder_encoder_attentions = [], []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            decoder_output, decoder_attention, decoder_encoder_attention = layer(decoder_output, encoder_output, attention_mask)\n",
    "            decoder_attentions.append(decoder_attention)\n",
    "            decoder_encoder_attentions.append(decoder_encoder_attention)\n",
    "            \n",
    "        return decoder_output, decoder_attentions, decoder_encoder_attentions\n",
    "    \n",
    "    def get_attention_mask(seq_q, seq_k):\n",
    "        batch_size, len_q = seq_q.size()\n",
    "        batch_size, len_k = seq_k.size()\n",
    "        pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q)\n",
    "    \n",
    "        return pad_attn_mask.expand(batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self):\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.linear_transform_layer = Dense(d_model, use_bias=False)\n",
    "        \n",
    "    def get_position(self, x):\n",
    "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "        \n",
    "        return pos * mask\n",
    "    \n",
    "    def compile(self, optimizer='adam'):\n",
    "        print(\">> Start Compile\")\n",
    "        source_input = Input(shape=(None,), dtype='int32')\n",
    "        target_input = Input(shape=(None,), dtype='int32')\n",
    "        \n",
    "        print(\">> Set Encoder\")\n",
    "        encoder_output = self.encoder(source_input)\n",
    "        print(\">> Set Decoder\")\n",
    "        decoder_output = self.decoder(target_input, source_input, encoder_output)\n",
    "        final_output = self.linear_transform_layer(decoder_output)\n",
    "        \n",
    "        def get_loss(args):\n",
    "            y_pred, y_true = args\n",
    "            y_true = tf.cast(y_true, 'int32')\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            loss = tf.reduce_sum(loss * mask, -1) / tf.reduce_sum(mask, -1)\n",
    "            loss = K.mean(loss)\n",
    "            return loss\n",
    "\n",
    "        def get_accu(args):\n",
    "            y_pred, y_true = args\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            corr = K.cast(K.equal(K.cast(y_true, 'int32'), K.cast(K.argmax(y_pred, axis=-1), 'int32')), 'float32')\n",
    "            corr = K.sum(corr * mask, -1) / K.sum(mask, -1)\n",
    "            return K.mean(corr)\n",
    "        \n",
    "        loss = Lambda(get_loss)([final_output, target_true])\n",
    "        self.ppl = Lambda(K.exp)(loss)\n",
    "        self.accu = Lambda(get_accu)([final_output, target_true])\n",
    "\n",
    "        self.model = Model([source_input, target_input], loss)\n",
    "        self.model.add_loss([loss])\n",
    "        self.output_model = Model([source_input, target_input], final_output)\n",
    "\n",
    "        self.model.compile(optimizer, None)\n",
    "        self.model.metrics_names.append('ppl')\n",
    "        self.model.metrics_tensors.append(self.ppl)\n",
    "        self.model.metrics_names.append('accu')\n",
    "        self.model.metrics_tensors.append(self.accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transformer = Transformer()\n",
    "\n",
    "transformer.compile(Adam(0.001, 0.9, 0.98, epsilon=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RNN]",
   "language": "python",
   "name": "conda-env-RNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
