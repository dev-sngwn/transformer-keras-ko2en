{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from h5py import File\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.initializers import *\n",
    "from keras.activations import *\n",
    "import tensorflow as tf\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "\n",
    "# Data Parameters\n",
    "data_file = 'data/en2de.h5'\n",
    "valid_data_file = 'data/en2de.valid.h5'\n",
    "dict_file = 'data/en2de_word.txt'\n",
    "\n",
    "# Transformer Parameters\n",
    "d_model = 512 # Embedding Demension\n",
    "d_ff = 2048 # Feed-Forward Network's Hidden Size\n",
    "d_k = d_v = 64 # = d_model / head\n",
    "N = 6 # Num of Encoder / Decoder Layer's Stack 6\n",
    "head = 8 # Num of Multi-Head Attention's Head 8\n",
    "len_limit = 999\n",
    "\n",
    "dropout = 0.1 # Dropout\n",
    "warmup_steps = 4000 # Using When Evaluate Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We use En2De Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English DictNum: 3369\n",
      "Deutsche DictNum: 3665\n",
      "Train Shapes: (29000, 43) (29000, 47)\n",
      "Valid Shapes: (1014, 34) (1014, 39)\n"
     ]
    }
   ],
   "source": [
    "class TokenList:\n",
    "    def __init__(self, token_list):\n",
    "        self.id2t = ['<PAD>', '<UNK>', '<S>', '</S>'] + token_list\n",
    "        self.t2id = {v: k for k, v in enumerate(self.id2t)}\n",
    "\n",
    "    def id(self, x):    \n",
    "        return self.t2id.get(x, 1)\n",
    "\n",
    "    def token(self, x):    \n",
    "        return self.id2t[x]\n",
    "\n",
    "    def num(self):        \n",
    "        return len(self.id2t)\n",
    "\n",
    "    def start_id(self):  \n",
    "        return 2\n",
    "\n",
    "    def end_id(self):    \n",
    "        return 3\n",
    "    \n",
    "\n",
    "def make_dict(dict_file):\n",
    "    with open(dict_file, encoding=\"utf-8\") as f:\n",
    "        _list = list(ll for ll in f.read().split('\\n') if ll != \"\")\n",
    "    mid_pos = _list.index('<@@@>') # Seperate En & De\n",
    "    input_tokens = TokenList(_list[:mid_pos])\n",
    "    output_tokens = TokenList(_list[mid_pos + 1:])\n",
    "    \n",
    "    return input_tokens, output_tokens\n",
    "\n",
    "\n",
    "def make_data(data_file):\n",
    "    with File(data_file) as df:\n",
    "        X, Y = df['X'][:], df['Y'][:]\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_tokens, output_tokens = make_dict(dict_file)\n",
    "    x_train, y_train = make_data(data_file)\n",
    "    x_valid, y_valid = make_data(valid_data_file)\n",
    "\n",
    "    input_vocab_size = input_tokens.num()\n",
    "    output_vocab_size = output_tokens.num()\n",
    "    \n",
    "    print('English DictNum:', input_tokens.num())\n",
    "    print('Deutsche DictNum:', output_tokens.num())\n",
    "    print('Train Shapes:',  x_train.shape, y_train.shape)\n",
    "    print('Valid Shapes:', x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(max_len):\n",
    "    PE = np.array([\n",
    "        [pos / np.power(10000, 2 * i / d_model) for i in range(d_model)]\n",
    "        if pos != 0 else np.zeros(d_model) for pos in range(max_len)\n",
    "    ]) # np.power(10000, 2 * (j // 2) / d_emb) ??? Why?\n",
    "    PE[1:, 0::2] = np.sin(PE[1:, 0::2]) # 2i\n",
    "    PE[1:, 1::2] = np.cos(PE[1:, 1::2]) # 2i + 1\n",
    "    \n",
    "    return PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self):\n",
    "        print(\"# Generated: Multi-Head Attention Layer\")\n",
    "        self.Q_linear_transform_layers = []\n",
    "        self.K_linear_transform_layers = []\n",
    "        self.V_linear_transform_layers = []\n",
    "        \n",
    "        for _ in range(head):\n",
    "            self.Q_linear_transform_layers.append(Dense(d_k, use_bias=False))\n",
    "            self.K_linear_transform_layers.append(Dense(d_k, use_bias=False))\n",
    "            self.V_linear_transform_layers.append(Dense(d_v, use_bias=False))\n",
    "        \n",
    "        self.normarlization_layer = LayerNormalization()\n",
    "        self.output_linear_transfrom_layer = Dense(d_model)\n",
    "        \n",
    "    def __call__(self, Q, K, V, mask=None):\n",
    "        print(\"# Executed: Multi-Head Attention\")\n",
    "        outputs = []\n",
    "        \n",
    "        for i in range(head):\n",
    "            WQ = self.Q_linear_transform_layers[i](Q)\n",
    "            WK = self.K_linear_transform_layers[i](K)\n",
    "            WV = self.V_linear_transform_layers[i](V)\n",
    "            output = self.scaled_dot_product_attention(WQ, WK, WV)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        output_result = Concatenate()(outputs)\n",
    "        output = self.output_linear_transfrom_layer(output_result)\n",
    "        output = Add()([output, Q])\n",
    "        \n",
    "        return self.normarlization_layer(output)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        attention = Lambda(lambda x: tf.matmul(x[0], x[1]) / np.sqrt(d_model))([Q, tf.transpose(K, perm=[0, 2, 1])])\n",
    "        attention = Lambda(lambda x: tf.matmul(x[0], x[1]))([(softmax(attention), V)])\n",
    "        \n",
    "        return attention\n",
    "\n",
    "    def scaled_dot_product_attention(self, q, k, v):\n",
    "        attention = Lambda(lambda x:tf.matmul(x[0],x[1]) / np.sqrt(d_model))([q, k])\n",
    "        attention = Activation('softmax')(attention)\n",
    "        output = Lambda(lambda x:tf.matmul(x[0], x[1]))([attention, v])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Position-wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForwardNetwork:\n",
    "    def __init__(self):\n",
    "        print(\"# Generated: Position-Wise Feed Forward Network\")\n",
    "        self.linear_transform_layer_1 = Dense(d_model)\n",
    "        self.relu_layer = Dense(d_model, activation='relu')\n",
    "        self.linear_transform_layer_2 = Dense(d_model)\n",
    "        self.normarlization_layer = LayerNormalization()\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        output = self.linear_transform_layer_1(x)\n",
    "        output = self.relu_layer(output)\n",
    "        output = self.linear_transform_layer_2(output)\n",
    "        output = Add()([output, x])\n",
    "        \n",
    "        return self.normarlization_layer(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer:\n",
    "    def __init__(self):\n",
    "        print(\"# Generated: Encoder Layer\")\n",
    "        self.multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.position_wise_feed_forward_network = PositionWiseFeedForwardNetwork()\n",
    "        \n",
    "    def __call__(self, encoder_input, mask=None):\n",
    "        encoder_output = self.multi_head_attention_layer(encoder_input, encoder_input, encoder_input, mask)\n",
    "        encoder_output = self.position_wise_feed_forward_network(encoder_output)\n",
    "        \n",
    "        return encoder_output\n",
    "    \n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.input_embedding =  Embedding(input_vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(len_limit, d_model, trainable=False, weights=[positional_encoding(len_limit)])\n",
    "        self.layers = [EncoderLayer() for _ in range(N)]\n",
    "        \n",
    "    def __call__(self, encoder_input, source_position):\n",
    "        encoder_output = Add()([self.input_embedding(encoder_input), self.positional_embedding(source_position)])\n",
    "\n",
    "        for layer in self.layers:\n",
    "            encoder_output = layer(encoder_output)\n",
    "            \n",
    "        return encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer:\n",
    "    def __init__(self):\n",
    "        print(\"# Generated: Decoder Layer\")\n",
    "        self.masked_multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.multi_head_attention_layer = MultiHeadAttention()\n",
    "        self.position_wise_feed_forward_network = PositionWiseFeedForwardNetwork()\n",
    "        \n",
    "    def __call__(self, decoder_input, encoder_output, mask=None):\n",
    "        decoder_output = self.masked_multi_head_attention_layer(decoder_input, decoder_input, decoder_input, mask)\n",
    "        decoder_output = self.multi_head_attention_layer(decoder_output, encoder_output, encoder_output, None)\n",
    "        decoder_output = self.position_wise_feed_forward_network(decoder_output)\n",
    "        \n",
    "        return decoder_output\n",
    "        \n",
    "class Decoder:\n",
    "    def __init__(self):\n",
    "        self.output_embedding =  Embedding(output_vocab_size, d_model)\n",
    "        self.positional_embedding = Embedding(len_limit, d_model, trainable=False, weights=[positional_encoding(len_limit)])\n",
    "        self.layers = [DecoderLayer() for _ in range(N)]\n",
    "        \n",
    "    def __call__(self, decoder_input, target_position, encoder_input, encoder_output):\n",
    "        decoder_output = Add()([self.output_embedding(decoder_input), self.positional_embedding(target_position)])\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            decoder_output = layer(decoder_output, encoder_output)\n",
    "            \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    def __init__(self):\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.linear_transform_layer = TimeDistributed(Dense(output_tokens.num(), use_bias=False))\n",
    "        \n",
    "    def get_position(self, x):\n",
    "        mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "        pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "        \n",
    "        return pos * mask\n",
    "    \n",
    "    def compile(self, optimizer='adam'):\n",
    "        print(\">> Start Compile ===========================================================================\")\n",
    "        source_input = Input(shape=(None,), dtype='int32')\n",
    "        target_input = Input(shape=(None,), dtype='int32')\n",
    "        \n",
    "        target_sequence = Lambda(lambda x:x[:, :-1])(target_input)\n",
    "        target_true = Lambda(lambda x:x[:, 1:])(target_input)\n",
    "        \n",
    "        def get_sequence_position(x):\n",
    "            mask = K.cast(K.not_equal(x, 0), 'int32')\n",
    "            pos = K.cumsum(K.ones_like(x, 'int32'), 1)\n",
    "            return pos * mask\n",
    "        \n",
    "        print(\">> Set Encoder =============================================================================\")\n",
    "        source_position = Lambda(get_sequence_position)(source_input)\n",
    "        encoder_output = self.encoder(source_input, source_position)\n",
    "        print(\">> Set Decoder =============================================================================\")\n",
    "        target_position = Lambda(get_sequence_position)(target_sequence)\n",
    "        decoder_output = self.decoder(target_sequence, target_position, source_input, encoder_output)\n",
    "        final_output = self.linear_transform_layer(decoder_output)\n",
    "        \n",
    "        def get_loss(args):\n",
    "            y_pred, y_true = args\n",
    "            y_true = tf.cast(y_true, 'int32')\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            loss = tf.reduce_sum(loss * mask, -1) / tf.reduce_sum(mask, -1)\n",
    "            loss = K.mean(loss)\n",
    "            return loss\n",
    "\n",
    "        def get_accu(args):\n",
    "            y_pred, y_true = args\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), 'float32')\n",
    "            corr = K.cast(K.equal(K.cast(y_true, 'int32'), K.cast(K.argmax(y_pred, axis=-1), 'int32')), 'float32')\n",
    "            corr = K.sum(corr * mask, -1) / K.sum(mask, -1)\n",
    "            return K.mean(corr)\n",
    "        \n",
    "        print(\">> Set Loss ================================================================================\")\n",
    "\n",
    "        loss = Lambda(get_loss)([final_output, target_true])\n",
    "        self.ppl = Lambda(K.exp)(loss)\n",
    "        self.accu = Lambda(get_accu)([final_output, target_true])\n",
    "        \n",
    "        print(\">> Set Model ===============================================================================\")\n",
    "\n",
    "        self.model = Model([source_input, target_input], loss)\n",
    "        self.model.add_loss([loss])\n",
    "        self.output_model = Model([source_input, target_input], final_output)\n",
    "\n",
    "        self.model.compile(optimizer, None)\n",
    "        self.model.metrics_names.append('ppl')\n",
    "        self.model.metrics_tensors.append(self.ppl)\n",
    "        self.model.metrics_names.append('accu')\n",
    "        self.model.metrics_tensors.append(self.accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Encoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      "# Generated: Decoder Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Multi-Head Attention Layer\n",
      "# Generated: Position-Wise Feed Forward Network\n",
      ">> Start Compile ===========================================================================\n",
      ">> Set Encoder =============================================================================\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      ">> Set Decoder =============================================================================\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      "# Executed: Multi-Head Attention\n",
      ">> Set Loss ================================================================================\n",
      ">> Set Model ===============================================================================\n",
      ">> Start Training\n",
      "Train on 29000 samples, validate on 1014 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer()\n",
    "\n",
    "transformer.compile(Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n",
    "\n",
    "print(\">> Start Training\")\n",
    "\n",
    "transformer.model.fit([x_train, y_train], None, batch_size=4, epochs=30,\n",
    "                     validation_data=([x_valid, y_valid], None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RNN]",
   "language": "python",
   "name": "conda-env-RNN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
